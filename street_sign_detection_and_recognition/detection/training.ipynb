{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6436bc51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/therandomtroll/miniconda3/envs/tf/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "Requirement already satisfied: pip in /home/therandomtroll/miniconda3/envs/tf-fallback/lib/python3.7/site-packages (22.3.1)\n",
      "Requirement already satisfied: install in /home/therandomtroll/miniconda3/envs/tf-fallback/lib/python3.7/site-packages (1.3.5)\n",
      "Requirement already satisfied: protobuf==3.20.* in /home/therandomtroll/miniconda3/envs/tf-fallback/lib/python3.7/site-packages (3.20.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pip install protobuf==3.20.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88c3381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "from sklearn import metrics\n",
    "from tensorflow.keras import utils\n",
    "\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from matplotlib import pyplot\n",
    "from numpy import expand_dims\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88e469e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_df = pd.read_csv(f'FullIJCNN2013/gt.txt',names=['file','x1','y1','x2','y2','class'],delimiter = ';')\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80a49ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#blue circle signs\n",
    "zero = [33,34,35,36,37,38,39,40]\n",
    "#b/w stripe circle\n",
    "one = [6,32,41,42]\n",
    "#danger\n",
    "two = [17]\n",
    "#diamond\n",
    "three = [12]\n",
    "#red circle\n",
    "four = [0,1,2,3,4,5,7,8,9,10,15,16]\n",
    "#red down triangle\n",
    "five = [13]\n",
    "#red up triangle\n",
    "six = [11,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
    "#stop\n",
    "seven = [14]\n",
    "\n",
    "subclass_list = [zero, one, two, three, four, five, six, seven]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfa56e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement image subclass from above\n",
    "def find_subclass(classid):\n",
    "    for i in range(8):\n",
    "        if classid in subclass_list[i]:\n",
    "            return i\n",
    "label_df['sub_class']=label_df['class'].map(find_subclass)\n",
    "label_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf543cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(900):\n",
    "    image_id = str(j).rjust(5,'0')\n",
    "    f_out = open(f'FullIJCNN2013/xml/{image_id}.xml','w')\n",
    "    f_out.write(f\"\"\"<annotation>\n",
    "    <folder>{f'FullIJCNN2013/'}</folder>\n",
    "    <path>{f'FullIJCNN2013/{image_id}.ppm'}</path>\n",
    "    <source>\n",
    "        <database>Unknown</database>\n",
    "    </source>\n",
    "    <filename>{str(j).rjust(5,'0')}.ppm</filename>\n",
    "    <size>\n",
    "        <width>1360</width>\n",
    "        <height>800</height>\n",
    "        <depth>3</depth>\n",
    "    </size>\n",
    "    <segmented>0</segmented>\n",
    "\"\"\")\n",
    "    temp_df = label_df[label_df['file'] == image_id+'.ppm']\n",
    "    for i in range(temp_df.shape[0]):\n",
    "        f_out.write(f\"\"\"    <object>\n",
    "        <name>{temp_df.iloc[i,6]+1}</name>\n",
    "        <pose>Unspecified</pose>\n",
    "        <truncated>0</truncated>\n",
    "        <difficult>0</difficult>\n",
    "        <bndbox>\n",
    "            <xmin>{temp_df.iloc[i,1]}</xmin>\n",
    "            <ymin>{temp_df.iloc[i,2]}</ymin>\n",
    "            <xmax>{temp_df.iloc[i,3]}</xmax>\n",
    "            <ymax>{temp_df.iloc[i,4]}</ymax>\n",
    "        </bndbox>\n",
    "    </object>\n",
    "\"\"\")        \n",
    "    f_out.write(\"</annotation>\")\n",
    "    f_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce98075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoadDataset(Dataset):\n",
    "    #Load the model\n",
    "    #is_train loads the set type, dataset_dir is where images are\n",
    "    #train_list and test_list to differntiate which file is what set\n",
    "    def load_dataset(self, dataset_dir,is_train=True):\n",
    "        #Two categories, normal and not\n",
    "        for i in range(8):\n",
    "            self.add_class('dataset',i+1,str(i+1))\n",
    "        files = glob.glob(dataset_dir + 'normalized/*.ppm')\n",
    "        for file in files:\n",
    "            image_idstr = file[-14:-9]\n",
    "            image_id = int(image_idstr)\n",
    "            if is_train and image_id >= 600:\n",
    "                continue\n",
    "            elif not is_train and image_id < 600:\n",
    "                continue\n",
    "            img_path = file\n",
    "            ann_path = f'{dataset_dir}xml/{image_idstr}.xml'\n",
    "            # add to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, \n",
    "                       annotation=ann_path,class_ids=[0,1,2])\n",
    "        \n",
    "    def extract_boxes(self, filename):\n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//object'):\n",
    "            name = box.find('name').text\n",
    "            xmin = int(box.find('./bndbox/xmin').text)\n",
    "            ymin = int(box.find('./bndbox/ymin').text)\n",
    "            xmax = int(box.find('./bndbox/xmax').text)\n",
    "            ymax = int(box.find('./bndbox/ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax, name]\n",
    "            boxes.append(coors)\n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        # print(boxes)\n",
    "        return boxes, width, height\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        # define box file location\n",
    "        path = info['annotation']\n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = int(box[4])\n",
    "            class_ids.append(self.class_names.index(str(box[4])))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3026c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a configuration for the model\n",
    "class RoadConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"road_cfg\"\n",
    "    # number of classes (background + num signs) (8 for sub cats, 43 for all signs)\n",
    "    NUM_CLASSES = 1 + 8\n",
    "    DETECTION_MIN_CONFIDENCE = 0.5\n",
    "    # number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = 131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caaadc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictionConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = \"road_cfg\"\n",
    "    # number of classes (background + num signs)\n",
    "    NUM_CLASSES = 1 + 8\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "    DETECTION_MIN_CONFIDENCE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea769a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make train dataset\n",
    "train_set = RoadDataset()\n",
    "train_set.load_dataset('FullIJCNN2013/',is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1edd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make test dataset\n",
    "test_set = RoadDataset()\n",
    "test_set.load_dataset('FullIJCNN2013/',is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fcbdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = RoadConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f5a6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MaskRCNN(mode='training', model_dir='../models', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('mask_rcnn_coco.h5',\n",
    "                   by_name=True\n",
    "                   ,exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "                            \"mrcnn_bbox\", \"mrcnn_mask\"]\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cef5e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=45, layers='heads')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "25cbba7859d823ebebe9b4a67ada74939d980bc5207c322f6666619ce5aa4c6c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
